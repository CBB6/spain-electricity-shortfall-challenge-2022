# SPAIN-ELECTRICITY SHORTFALL 2022
* This project is part of the EDSA advanced regression sprint. Explores various regression models to predict Spain's three hourly energy short falls. The project is created and presented by team CBB6.

# TEAM CBB6
  * Thulani Nyama
  * Mike Ngwenya
  * Tsikelelo Ngcai
  * Tumishang Mankoe
  * Pamela Bokaba
  * Lungelo Ndlovu
	

# PROBLEM STATEMENT
*	Spain experiences daily three hourly shortfalls of energy generated by means of fossil fuels and various renewable sources. Electricity is an essential service, the use of purely non-renewable sources is not sustainable.
# PROBLEM LANDSCAPE
*	This project aims to create a regression model that will accurately predict the difference between the energy generated by the method of renewable energy sources and energy generated with fossil fuels partitioned in three-hour windows.
# DATA SOURCES
*	The Spain energy shortfall data was retrieved  from Kaggle (https://www.kaggle.com/datasets/nicholasjhana/energy-consumption-generation-prices-and-weather)  
*	Consumption and generation data was retrieved from ENTSOE a public portal for Transmission Service Operator (TSO) data (https://transparency.entsoe.eu/dashboard/show)
*	 The weather data obtained from (Open Weather API ) directory link (https://openweathermap.org/api) 


# TOOLS
*	Jupyter notebook application
*	Kaggle application
*	Trello application
*	Github application
*	Gitbash/ Visual Studio Code application
*	AWS application
*	Python language
*	Python libraries 
# APPLICATION LINKS 
* The following links are for signing up for the tools that have been used in the project.
    *	https://jupyter.org/install
    * https://www.kaggle.com/
    *	https://trello.com/signup
    *	https://github.com/
	  * https://www.makeuseof.com/install-git-git-bash-windows/
    *	https://aws.amazon.com/resources/create-account/
# Python Libraries
*	The following are the python packages that have been used in the project
*	Libraries for data loading, data manipulation and data visulisation
    * import warnings
    * import numpy as np
    * import pandas as pd
    * import seaborn as sns 
    * import datetime as dt
    * import matplotlib.pyplot as plt

 * Libraries for data preparation and model building
    * import matplotlib.pyplot as plt
    * from sklearn.preprocessing import OrdinalEncoder, StandardScaler
    * from sklearn.model_selection import train_test_split , cross_validate
    * Setting global constants to ensure notebook results are reproducible
    * from sklearn.feature_selection import RFE
    * warnings.filterwarnings('ignore')
    * from sklearn.tree import DecisionTreeRegressor
    * import sklearn.neural_network as NNR
    * from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, AdaBoostRegressor
    * from sklearn.metrics import mean_squared_error as mse
    * import math
    * from statsmodels.graphics.correlation import plot_corr
    * import statsmodels.formula.api as sm
    *	from statsmodels.formula.api import ols
	  *  %matplotlib inline
    
# Project tasks
*	Exploratory data analyses (EDA)
    * In depth analyses of the data
    * Plotting relevant feature interactions
    * Plotting correlation heat map for predictor variable
    * Mask top half of matrix as it contains redundant info
    * Plotting the matrix
    * Plotting distributions of all the features in train
    * Analyze  feature distributions
    * Check for missing values
    * Plot missing values
    
	# Data Engineering
    * Gather mode from  data sets to replace missing values
    * Remove missing values/features
    * Plot missing values in train set
    * Create new features
    * Impute Categorical features using OrdinalEncoder()
    * Transform Features
    * Engineer existing features
    * Scale the dataset
    * Add load_short_fall_3h as last_columns on training data
    
	# Modelling
    * Split data
    * Add load_short_fall_3h as last columns on training data
    * Checking the shape of the training and testing data
    * Create targets and features dataset
    * Create one or more ML models
    * Ensemble with Bagging
    * Ensemble with AdaBost
    * Train Bagging ensemble models
    * Train AdaBoost ensemble models
    * Get Bagging ensemble predictions
    * Evaluate  ML models
   
	# Model Performance
    * Compare model performance
    * Create dataframe from dictionary
    * Choose best model
  
	# API tasks
    * Fork the Explore repo
    * Install flask, numpy, pandas and scikit-learn using pip
    * Change preprocessing functions in model.py to work with new features. 
    * Change the output of the pkl file.
    * Run train_model.py to pickle our model
    * Point api.py to our new model.
    *  Run api.py
    * Run request.py to test output
    
	# Deploying to AWS
    * Login to AWS console.
    * Launch an EC2 instance.
    * Connect to EC2 using EC2-connect or SSH client.
    * Install python using yum.
    * Install flask, numpy, pandas and scikit-learn using pip.
    * Install git using yum.
    * Clone the API from Github using git
    * Run the API as a separate background process.
    * On your local machine, change the URL in request.py to point to the EC2
    * Run request.py to test output
  *
  
	 
â€¢	For more descriptive  steps on the Flask-based Model API  (https://github.com/CBB6/load-shortfall-regression-predict-api#readme) 


	

